

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction &mdash; SACRO-ML 1.4.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=9172181d"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Attacks" href="attacks/index.html" />
    <link rel="prev" title="Welcome to the SACRO-ML documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SACRO-ML
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-sacro-ml">What is SACRO-ML?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-safemodel">What is safemodel?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-are-simulated-attacks">What are simulated attacks?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="attacks/index.html">Attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="safemodel/index.html">Safemodel</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SACRO-ML</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Introduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/introduction.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h1>
<section id="what-is-sacro-ml">
<h2>What is SACRO-ML?<a class="headerlink" href="#what-is-sacro-ml" title="Link to this heading"></a></h2>
<a class="reference internal image-reference" href="_images/ML_leakage_bee.png"><img alt="Data breaches of sensitive and personal data must be avoided." class="align-center" src="_images/ML_leakage_bee.png" style="width: 320px; height: 350px;" />
</a>
<dl>
<dt>SACRO-ML is a set of tools for disclosure control of trained Machine Learning (ML)</dt><dd><p>models. ML models enable the discovery of intricate relationships that a human eye,
and traditional statistical methods can’t. These types of powerful tools are becoming</p>
<blockquote>
<div><p>increasingly popular in many different fields. These includes medical applications
and any project involving personal and sensitive data. Data breaches must be avoided.
SACRO-ML helps to apply some mitigation strategies like the use of safemodels and
estimate the risk of identifying any personal and sensitive data employed to build the ML model.</p>
</div></blockquote>
</dd>
</dl>
<p>It is especially designed bearing in mind data privacy and mitigation strategies for disclosure control.</p>
<dl>
<dt>Typically, sensitive data is accessed via a Trusted Research Environment (TRE) or Save Heaven, which</dt><dd><p>is a secure enclave. In such environments it is essential to check outputs before releasing them to
guarantee there is no data breach.</p>
<a class="reference internal image-reference" href="_images/TRE-project-outputcheck-overview.jpg"><img alt="Timeline of a life cycle of a ML model containing sensitive and personal data." class="align-center" src="_images/TRE-project-outputcheck-overview.jpg" style="width: 400px; height: 300px;" />
</a>
</dd>
</dl>
</section>
<section id="what-is-safemodel">
<h2>What is safemodel?<a class="headerlink" href="#what-is-safemodel" title="Link to this heading"></a></h2>
<p>The safemodel package is an open source wrapper for common machine learning
models. It is designed for use by researchers in Trusted Research Environments
(TREs) where disclosure control methods must be implemented.</p>
<p>Safemodel aims to give researchers greater confidence that their models are
more compliant with disclosure control.</p>
<p>Safemodel provides feedback to the researcher through a JSON parseable
‘checkfile’ report:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;researcher&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;andy&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;model_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;DecisionTreeClassifier&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;model_save_file&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unsafe.pkl&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;details&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WARNING: model parameters may present a disclosure risk:\n- para</span>
<span class="s2">meter min_samples_leaf = 1 identified as less than the recommended min value of</span>
<span class="s2">5.&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;recommendation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Do not allow release&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WARNING: model parameters may present a disclosure risk:\n- param</span>
<span class="s2">eter min_samples_leaf = 1 identified as less than the recommended min value of 5</span>
<span class="s2">.Error: user has not called fit() method or has deleted saved values.Recommendat</span>
<span class="s2">ion: Do not release.&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="what-are-simulated-attacks">
<h2>What are simulated attacks?<a class="headerlink" href="#what-are-simulated-attacks" title="Link to this heading"></a></h2>
<p>Simulated attacks are those scenarios where a ML is attacked under controlled circumstances,
and the risk of data breach is estimated. It may be used before releasing a ML model
publicly to ensure privacy.</p>
<section id="when-can-sacro-ml-attack-simulation-be-used">
<h3>When can SACRO-ML attack simulation be used?<a class="headerlink" href="#when-can-sacro-ml-attack-simulation-be-used" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>When an ML model has been trained with sensitive data and want to avoid data leakage.</p></li>
<li><p>The model does not contain embedded data points. Find <a href="#id1"><span class="problematic" id="id2">`</span></a>an example</p></li>
</ul>
<p>&lt;<a class="reference external" href="https://github.com/AI-SDC/SACRO-ML/blob/329-add-more-documentation/examples/risk_examples/python/instance_based_mimic.ipynb">https://github.com/AI-SDC/SACRO-ML/blob/329-add-more-documentation/examples/risk_examples/python/instance_based_mimic.ipynb</a>&gt;`_
of issues with instance-based ML models.
- When the test data has not been seen by the trained model. Any data point seen by the
model during the training phase is considered part of the training data.
- The test data must have ideally 30 to 50% of the original set, and at least 20%.
- For models which predict with numerical values as opposed to binary (i.e. yes|no).</p>
</section>
<section id="what-sacro-ml-attack-simulation-is-not-intended-for">
<h3>What SACRO-ML attack simulation is not intended for?<a class="headerlink" href="#what-sacro-ml-attack-simulation-is-not-intended-for" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>For anonymous and non-sensitive datasets.</p></li>
<li><p>For those ML models which contain embedded data. For example, instance-based methods</p></li>
</ul>
<p>including: K-nearest neighbours (KNN), Super Vector Classifier, (SVC), Self
Organising Map (SOM), Learning Vector Quantization (LVQ), Locally Weighted Learning
(LWL), Case-Based Reasoning, Gaussian Process, Kernel-based models, etc. These models
are breaching data.
- Many of the deep learning models are at high risk of including data careful consideration should
be applied before using SACRO-ML.
- When there is no test data, or the test data has been seen by the model during the training phase.
- For any other concern that the trained model might be at risk of data breach.
- When less than 20% of the data is available (from the original dataset) for the simulated attacks.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to the SACRO-ML documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="attacks/index.html" class="btn btn-neutral float-right" title="Attacks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, GRAIMATTER and SACRO Project Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>